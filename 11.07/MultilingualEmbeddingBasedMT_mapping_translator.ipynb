{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Сафарян ДЗ 6 MultilingualEmbeddingBasedMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiBke0acKu82",
        "colab_type": "text"
      },
      "source": [
        "# Для начала главное\n",
        "Вот Вам именинный котя, милый и залипательный :3\n",
        "\n",
        "![alt text](https://bit.ua/wp-content/uploads/2013/12/giphy-4.gif)\n",
        "\n",
        "\n",
        "А теперь уже можно и к домашкам там всяким переходить)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljB2IlGyckN",
        "colab_type": "text"
      },
      "source": [
        "# Отчёт"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2rxtkpS0Ltp",
        "colab_type": "text"
      },
      "source": [
        "Мы попробовали 2 способа совместить пространства эмбеддингов для разных языков: обучив регрессор и через разложение матриц. Через SVD получается намного лучше, а учитывая небольшую разницу между точностью в первом варианте и точностью в первых пяти, можно сказать, что большинство правильных переводов предлагаются первым вариантом.\n",
        "\n",
        "Мы даже сделали на основе SVD переводчик, правда, он пословный и глупенький."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJEdq2w8xgpx",
        "colab_type": "code",
        "outputId": "87f0e035-6300-41f9-fba7-f81065a68d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('''\\tRegression\\t\\tSVD\n",
        "TOP-1:\\t{}\\t{}\n",
        "TOP-5:\\t{}\\t{}\n",
        "'''.format(map_precision_1, map_precision_5, svd_precision_1, svd_precision_5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tRegression\t\tSVD\n",
            "TOP-1:\t0.6356589147286822\t0.813953488372093\n",
            "TOP-5:\t0.6537467700258398\t0.8242894056847545\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbH9xgSLxEjZ",
        "colab_type": "text"
      },
      "source": [
        "#Homework: Multilingual Embedding-based Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4wb2coTxEjd",
        "colab_type": "text"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully). \n",
        "\n",
        "For our system we choose two kindred Slavic languages: Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUgPsacxEjj",
        "colab_type": "text"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZwe7gLD4UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amrWdtb8xEjp",
        "colab_type": "text"
      },
      "source": [
        "Download embeddings here:\n",
        "* [cc.uk.300.vec.zip](https://yadi.sk/d/9CAeNsJiInoyUA)\n",
        "* [cc.ru.300.vec.zip](https://yadi.sk/d/3yG0-M4M8fypeQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRRPMRad3by2",
        "colab_type": "code",
        "outputId": "622cbf28-e4d8-4fc5-8bbc-f381e22c50b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "!wget  https://www.dropbox.com/s/mqmilqwlo8o81vi/cc.uk.300.vec.zip\n",
        "!unzip cc.uk.300.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-16 15:26:54--  https://drive.google.com/file/d/1Hn7XcwT5Sq72FlMiwK0yWj9yH8gVryON/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.141.113, 74.125.141.100, 74.125.141.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.141.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view?usp=sharing’\n",
            "\n",
            "\rview?usp=sharing        [<=>                 ]       0  --.-KB/s               \rview?usp=sharing        [ <=>                ] 119.82K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2019-05-16 15:26:54 (12.8 MB/s) - ‘view?usp=sharing’ saved [122695]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH4sbSw1EJXb",
        "colab_type": "code",
        "outputId": "1648b20b-c4c6-4312-bc4f-015997cf5444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "!wget  https://www.dropbox.com/s/nvhpu2dfinbbtqq/cc.ru.300.vec.zip\n",
        "!unzip cc.ru.300.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-03 15:40:31--  https://www.dropbox.com/s/nvhpu2dfinbbtqq/cc.ru.300.vec.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/nvhpu2dfinbbtqq/cc.ru.300.vec.zip [following]\n",
            "--2019-03-03 15:40:31--  https://www.dropbox.com/s/raw/nvhpu2dfinbbtqq/cc.ru.300.vec.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com/cd/0/inline/AcY8sCS9S2dA7kgCvtBHP36FTwVBx-sqmmD93M6x40l3dxhdM6WHQFRx15vIoiTilsXwcDt00LdCCV41TyUgIhmbs9G4thK5Ugh2w7QqFKlRQnUsugIAn3T-cl2X9_XM9i4/file# [following]\n",
            "--2019-03-03 15:40:31--  https://uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com/cd/0/inline/AcY8sCS9S2dA7kgCvtBHP36FTwVBx-sqmmD93M6x40l3dxhdM6WHQFRx15vIoiTilsXwcDt00LdCCV41TyUgIhmbs9G4thK5Ugh2w7QqFKlRQnUsugIAn3T-cl2X9_XM9i4/file\n",
            "Resolving uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com (uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com (uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AcY8J6p1bn2mGsB6UHOtNeuWqZjqAoYBGzAuh6CWzHIMbKaI_tTsSzxZhisd8gbJwX2nHYursVgs3yWUesIAjOxEIzMghAIGGk4z_J0MlTV0-GT9udDZcSXYFgKDmNIt_-8hfacPXkP1cueVx0P8HD6mQQohFO2iktRskNHlq5iPCYVZPl3rSOxFd9-awET_7x2b5F4LsRNO12OzIZwTUtBMOwUR6nCq11IGtIWo0hluPiB3GBsS_mCow6kLWDDwWddKhCM4bj5VYfC1lNaC8FS9yf7nNQLIxn2ZzyIS4b9GIsxSq4Rzrcj36A6W8MGIa1cv28FriqK8bad6ngq-31ykWa0D1jloryzaGdP9-WZHCA/file [following]\n",
            "--2019-03-03 15:40:32--  https://uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com/cd/0/inline2/AcY8J6p1bn2mGsB6UHOtNeuWqZjqAoYBGzAuh6CWzHIMbKaI_tTsSzxZhisd8gbJwX2nHYursVgs3yWUesIAjOxEIzMghAIGGk4z_J0MlTV0-GT9udDZcSXYFgKDmNIt_-8hfacPXkP1cueVx0P8HD6mQQohFO2iktRskNHlq5iPCYVZPl3rSOxFd9-awET_7x2b5F4LsRNO12OzIZwTUtBMOwUR6nCq11IGtIWo0hluPiB3GBsS_mCow6kLWDDwWddKhCM4bj5VYfC1lNaC8FS9yf7nNQLIxn2ZzyIS4b9GIsxSq4Rzrcj36A6W8MGIa1cv28FriqK8bad6ngq-31ykWa0D1jloryzaGdP9-WZHCA/file\n",
            "Reusing existing connection to uc5ec767b544ac2979732a627e0f.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 397254664 (379M) [application/zip]\n",
            "Saving to: ‘cc.ru.300.vec.zip.1’\n",
            "\n",
            "cc.ru.300.vec.zip.1 100%[===================>] 378.85M  37.2MB/s    in 12s     \n",
            "\n",
            "2019-03-03 15:40:44 (32.7 MB/s) - ‘cc.ru.300.vec.zip.1’ saved [397254664/397254664]\n",
            "\n",
            "Archive:  cc.ru.300.vec.zip\n",
            "replace cc.ru.300.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cc.ru.300.vec           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sevsp92axEjq",
        "colab_type": "text"
      },
      "source": [
        "Load embeddings for ukrainian and russian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu4gwZQLxEjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTnVJf4hxEjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IT6dctZxEkC",
        "colab_type": "text"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5NEsSUUTNsA",
        "colab_type": "code",
        "outputId": "aef19e2b-0bd5-4069-abbf-56d78a0199b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/fairy_tale.txt  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-03 15:45:57--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59351 (58K) [text/plain]\n",
            "Saving to: ‘ukr_rus.train.txt.1’\n",
            "\n",
            "\rukr_rus.train.txt.1   0%[                    ]       0  --.-KB/s               \rukr_rus.train.txt.1 100%[===================>]  57.96K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-03 15:45:57 (2.76 MB/s) - ‘ukr_rus.train.txt.1’ saved [59351/59351]\n",
            "\n",
            "--2019-03-03 15:45:59--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12188 (12K) [text/plain]\n",
            "Saving to: ‘ukr_rus.test.txt.1’\n",
            "\n",
            "ukr_rus.test.txt.1  100%[===================>]  11.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-03 15:45:59 (118 MB/s) - ‘ukr_rus.test.txt.1’ saved [12188/12188]\n",
            "\n",
            "--2019-03-03 15:46:01--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/fairy_tale.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7461 (7.3K) [text/plain]\n",
            "Saving to: ‘fairy_tale.txt.1’\n",
            "\n",
            "fairy_tale.txt.1    100%[===================>]   7.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-03 15:46:01 (103 MB/s) - ‘fairy_tale.txt.1’ saved [7461/7461]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5qWWbm1xEkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrROf_lOxEkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9He0TQVfxEkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lohe2wojxEkQ",
        "colab_type": "text"
      },
      "source": [
        "## Embedding space mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AT75pQDxEkQ",
        "colab_type": "text"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm.\n",
        "\n",
        "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTFzES6NxEkS",
        "colab_type": "text"
      },
      "source": [
        "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3adCjMxEkS",
        "colab_type": "text"
      },
      "source": [
        "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjmtI57OxEkT",
        "colab_type": "text"
      },
      "source": [
        "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvu7JI5HxEkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mapping = LinearRegression(fit_intercept=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQR95u0J-tmt",
        "colab_type": "code",
        "outputId": "f855039a-3c71-4f01-f665-ba70f1502ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mapping.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None,\n",
              "         normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnn481MqxEkX",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXpBOlPtxEkY",
        "colab_type": "code",
        "outputId": "35b01ba7-502a-4c88-c9d5-e7b0dffc00fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8541285991668701),\n",
              " ('июнь', 0.8411202430725098),\n",
              " ('март', 0.839699387550354),\n",
              " ('сентябрь', 0.835986852645874),\n",
              " ('февраль', 0.8329296708106995),\n",
              " ('октябрь', 0.8311846256256104),\n",
              " ('ноябрь', 0.8278923034667969),\n",
              " ('июль', 0.8234529495239258),\n",
              " ('август', 0.8120501041412354),\n",
              " ('декабрь', 0.8039004802703857)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5zrzGF8xEkb",
        "colab_type": "text"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYHDQ8mJxEkf",
        "colab_type": "text"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNvFY3MqxEkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "        variants = ru_emb.most_similar(mapped_vectors[i].reshape(1, -1), topn=topn) # берём k предсказаний\n",
        "        #print(variants)\n",
        "        ru_variants = [variant[0] for variant in variants] # собираем список вариантов\n",
        "        #print(ru_variants)\n",
        "        if ru in ru_variants:\n",
        "          num_matches += 1\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCsr592-xEkj",
        "colab_type": "code",
        "outputId": "4393da90-275d-48ff-ae54-3e4b0ed3ac2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3gZtL3xxEko",
        "colab_type": "code",
        "outputId": "56294890-c1ce-4f18-8b75-de5a55eb7b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWgF-iVJxEkr",
        "colab_type": "code",
        "outputId": "829672ed-0f46-43c1-8021-48292a7cee4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02oyZVxWxEkv",
        "colab_type": "text"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjVq_9hOxEkw",
        "colab_type": "text"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21IGReUexEky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.linalg import svd\n",
        "\n",
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    U, S, V = svd(np.matmul(X_train.T, Y_train))\n",
        "    return np.matmul(U, V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "390Z0EcYxEk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2co0YXeTxEk3",
        "colab_type": "code",
        "outputId": "9a258416-839e-49a4-e015-1454e173a56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8237907290458679),\n",
              " ('сентябрь', 0.8049713373184204),\n",
              " ('март', 0.802565336227417),\n",
              " ('июнь', 0.8021842241287231),\n",
              " ('октябрь', 0.8001736402511597),\n",
              " ('ноябрь', 0.793448269367218),\n",
              " ('февраль', 0.7914119958877563),\n",
              " ('июль', 0.7908108234405518),\n",
              " ('август', 0.789101779460907),\n",
              " ('декабрь', 0.7686372995376587)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKsiCCs6xEk5",
        "colab_type": "code",
        "outputId": "9cd1a067-6c4e-4e20-e976-86c2b96d0dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
        "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr9NLQ1jxEk8",
        "colab_type": "text"
      },
      "source": [
        "## UK-RU Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTiCZF__xEk9",
        "colab_type": "text"
      },
      "source": [
        "Now we are ready to make simple word-based translator: for earch word in source language in shared embedding space we find the nearest in target language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LdkHxELxEk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as inpf:\n",
        "    uk_sentences = [line.rstrip().lower() for line in inpf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZQTwUacxElE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    translate = []\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      if token in uk_emb.vocab:\n",
        "        uk = np.matmul(uk_emb.get_vector(token), W) # матрицу W уже обучили\n",
        "        #print(uk)\n",
        "        ru = ru_emb.most_similar([uk], topn=1)[0][0] # берём слово из кортежа наиболее похожего вектора\n",
        "        #print(ru)\n",
        "        translate.append(ru)\n",
        "      else: # если такого токена нет в словаре, то оставим его так, но с пометочкой\n",
        "        translate.append('_'+token+'_')\n",
        "    return ' '.join(translate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU7-vL8JxElJ",
        "colab_type": "code",
        "outputId": "d26762de-d4e3-42f3-e9cb-c0c1f87b3afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMhuZyuJxElM",
        "colab_type": "code",
        "outputId": "4a1788a2-a668-405a-aea9-0a62eecc86e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3646
        }
      },
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"ukr: {}\\nrus: {}\\n\".format(sentence, translate(sentence)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ukr: лисичка - сестричка і вовк - панібрат\n",
            "rus: лисичка – сестричка и волк – _панібрат_\n",
            "\n",
            "ukr: як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !\n",
            "rus: как была себе лисичка , че и пошла раз к _однії_ бабы _добувать_ огня ; вошла во избу че и говорит : \" хороший день тебе , бабушку !\n",
            "\n",
            "ukr: дай мені огня \" .\n",
            "rus: дай мне огня \" .\n",
            "\n",
            "ukr: а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .\n",
            "rus: а бабка только что вынула со печи _пирожок_ со маком , сладкий , че и согнула , чтобы он _прохолов_ ; а лисичка ой и _підгледала_ , че токмо что бабка качнулась во печь , чтобы _достать_ огня , то лисичка сейчас _ухватила_ _пирожок_ че и деру со хаты , че , пробежать , весь мак со его _виїла_ , а туда мусора наложила .\n",
            "\n",
            "ukr: прибігла на поле , аж там пасуть хлопці бичків .\n",
            "rus: прибежала по поле , аж там пасут парни бычков .\n",
            "\n",
            "ukr: вона і каже їм : \" ей , хлопці !\n",
            "rus: она и говорит им : \" ой , парни !\n",
            "\n",
            "ukr: проміняйте мені бичка - третячка за маковий пирожок \" .\n",
            "rus: _проміняйте_ мне бычка – _третячка_ за маковый _пирожок_ \" .\n",
            "\n",
            "ukr: тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .\n",
            "rus: ишо поглумиться ; так она им говорит : \" _смотріть_ то , мы не ешьте сейчас сего _пирожка_ , а тогда уже _розломите_ , как мной _заведу_ бычка за могилу ; а то мы его ни за что не _розломите_ \" .\n",
            "\n",
            "ukr: бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .\n",
            "rus: вижу уже – лисичка таки себе была умная , что хоть кого че _обманить_ .\n",
            "\n",
            "ukr: тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .\n",
            "rus: ишо парни так и сделали , а лисичка как зашла за могилу , че сейчас во лес и вернула , чтобы по дороге не погнали ; пришла во лес че и сделала себе санки че и едет .\n",
            "\n",
            "ukr: коли йде вовчик : \" здорова була , лисичко - сестричко ! \"\n",
            "rus: когда идет _вовчик_ : \" здоровая была , _лисичко_ – сестричка ! \"\n",
            "\n",
            "ukr: - \" здоров , вовчику - братику ! \"\n",
            "rus: – \" здоровье , _вовчику_ – братику ! \"\n",
            "\n",
            "ukr: - \" де се ти узяла собі і бичка і санки ? \"\n",
            "rus: – \" куда ой ты взяла себе и бычка и санки ? \"\n",
            "\n",
            "ukr: - \" е !\n",
            "rus: – \" ьн !\n",
            "\n",
            "ukr: зробила \" .\n",
            "rus: сделала \" .\n",
            "\n",
            "ukr: - \" підвези ж і мене \" .\n",
            "rus: – \" _підвези_ же и меня \" .\n",
            "\n",
            "ukr: - \" е , вовчику !\n",
            "rus: – \" ьн , _вовчику_ !\n",
            "\n",
            "ukr: не можна \" .\n",
            "rus: не можно \" .\n",
            "\n",
            "ukr: - \" мені хоть одну ніжку \" .\n",
            "rus: – \" мне хоть одну ножку \" .\n",
            "\n",
            "ukr: - \" одну можна \" .\n",
            "rus: – \" одну можно \" .\n",
            "\n",
            "ukr: він і положив , да од'їхавши немного і просить , щоби іще одну положить .\n",
            "rus: он и положил , че от со проехав конешно и просит , чтобы еще одну возмет .\n",
            "\n",
            "ukr: \" не можна , братику !\n",
            "rus: \" не можно , братику !\n",
            "\n",
            "ukr: боюсь , щоб ти саней не зламав \" .\n",
            "rus: боюсь , чтобы ты саней не сломал \" .\n",
            "\n",
            "ukr: - \" ні , сестричко , не бійся ! \"\n",
            "rus: – \" ни , сестричка , не бойся ! \"\n",
            "\n",
            "ukr: - да і положив другую ніжку .\n",
            "rus: – че и положил одну ножку .\n",
            "\n",
            "ukr: тілько що од'їхали , як щось і тріснуло .\n",
            "rus: токмо что от со ехали , как что-то и треснуло .\n",
            "\n",
            "ukr: \" бачиш , вовчику , уже і ламаєш санки \" .\n",
            "rus: \" видишь , _вовчику_ , уже и _ламаєш_ санки \" .\n",
            "\n",
            "ukr: - \" ні , лисичко !\n",
            "rus: – \" ни , _лисичко_ !\n",
            "\n",
            "ukr: се у мене був орішок , так я розкусив \" .\n",
            "rus: ой во меня был _орішок_ , так мной _розкусив_ \" .\n",
            "\n",
            "ukr: да просить оп'ять , щоб і третю ногу положить ; лисичка і ту пустила , да тілько що оп'ять од'їхали , аж щось уже дужче тріснуло .\n",
            "rus: че просит т со пять , чтобы и третью ногу возмет ; лисичка и ту пустила , че токмо что т со пять от со ехали , аж что-то уже сильней треснуло .\n",
            "\n",
            "ukr: лисичка закричала : \" ох , лишечко !\n",
            "rus: лисичка закричала : \" ой , _лишечко_ !\n",
            "\n",
            "ukr: ти ж мені , братику , зовсім зламаєш санки \" .\n",
            "rus: ты же мне , братику , совсем _зламаєш_ санки \" .\n",
            "\n",
            "ukr: - \" ні , лисичко , се я орішок розкусив \" .\n",
            "rus: – \" ни , _лисичко_ , ой мной _орішок_ _розкусив_ \" .\n",
            "\n",
            "ukr: - \" дай же і мені , бачиш який , що сам їж , а мені і не даєш \" .\n",
            "rus: – \" дай то и мне , видишь который , что сам ел , а мне и не даешь \" .\n",
            "\n",
            "ukr: - \" нема уже більше , а я б дав \" .\n",
            "rus: – \" нету уже больше , а мной бы дал \" .\n",
            "\n",
            "ukr: да і просить оп'ять , щоб пустила положить і послідню ногу .\n",
            "rus: че и просит т со пять , чтобы пустила возмет и _послідню_ ногу .\n",
            "\n",
            "ukr: лисичка і согласилась .\n",
            "rus: лисичка и _согласилась_ .\n",
            "\n",
            "ukr: так він тілько що положив ногу , як санки зовсім розламались .\n",
            "rus: так он токмо что положил ногу , как санки совсем _розламались_ .\n",
            "\n",
            "ukr: тоді вже лисичка так на його розсердилась , що і сама не знала щоб робила !\n",
            "rus: тогда уже лисичка так по его _розсердилась_ , что и сама не знала чтобы делала !\n",
            "\n",
            "ukr: а як отошло серце , вона і каже : \" іди ж , ледащо !\n",
            "rus: а как _отошло_ сердце , она и говорит : \" иди же , лодырь !\n",
            "\n",
            "ukr: да нарубай дерева , щоб нам оп'ять ізробить санки ; тільки рубавши кажи так : \" рубайся ж , дерево , і криве і пряме \" .\n",
            "rus: че _нарубай_ деревья , чтобы нам т со пять _ізробить_ санки ; только _рубавши_ говори так : \" _рубайся_ же , дерево , и кривое и прямое \" .\n",
            "\n",
            "ukr: він і пішов да й каже усе : \" рубайся ж , дерево , усе пряме да пряме ! \"\n",
            "rus: он и пошел че и говорит всё : \" _рубайся_ же , дерево , всё прямое че прямое ! \"\n",
            "\n",
            "ukr: нарубавши і приносить ; лисичка увидала , що дерево не таке , як їй нужно , оп'ять розсердилась .\n",
            "rus: _нарубавши_ и приносит ; лисичка _увидала_ , что дерево не такое , как им надо , т со пять _розсердилась_ .\n",
            "\n",
            "ukr: \" ти , - говорить , - не казав , видно , так , як я тобі веліла ! \"\n",
            "rus: \" ты , – говорит , – не говорил , видно , так , как мной тебе велела ! \"\n",
            "\n",
            "ukr: - \" ні , я усе теє казав , що ти мені казала \" .\n",
            "rus: – \" ни , мной всё Эх говорил , что ты мне говорила \" .\n",
            "\n",
            "ukr: - \" да чомусь не таке рубалось ?\n",
            "rus: – \" че почему-то не такое _рубалось_ ?\n",
            "\n",
            "ukr: ну , сиди ж ти тут , а я сама піду нарубаю \" , - да і пішла у ліс .\n",
            "rus: ну , сиди же ты здесь , а мной сама пойду _нарубаю_ \" , – че и пошла во лес .\n",
            "\n",
            "ukr: а вовк дивиться , що він сам остався ; узяв да проїв у бичка дірку да виїв усе в середині , а напускав туда горобців да ще соломою заткнув , поставив бичка , а сам і втік .\n",
            "rus: а волк смотрит , что он сам остался ; взял че _проїв_ во бычка дыру че _виїв_ всё во середине , а _напускав_ туда воробьёв че ещe соломой заткнул , поставил бычка , а сам и сбежал .\n",
            "\n",
            "ukr: аж лисичка приходить , зробила санки да й сіла і стала поганять : \" гей , бичок - третячок ! \"\n",
            "rus: аж лисичка приходит , сделала санки че и присела и стала _поганять_ : \" гей , бычок – _третячок_ ! \"\n",
            "\n",
            "ukr: тілько він не везе .\n",
            "rus: токмо он не увозит .\n",
            "\n",
            "ukr: от вона встала , щоб поправить : може , що не так запряжено ; да , не хотячи , одоткнула солому , а оттуда так і сипнули горобці летіти .\n",
            "rus: из она встала , чтобы поправит : может , что не так _запряжено_ ; че , не вздумал , _одоткнула_ солому , а туды так и _сипнули_ воробьи лететь .\n",
            "\n",
            "ukr: вона уже тоді побачила , що бичок неживий ; покинула його да й пішла .\n",
            "rus: она уже тогда увидела , что бычок неживой ; покинула его че и пошла .\n",
            "\n",
            "ukr: легла на дорозі , аж дивиться - їде мужик з рибою ; вона і притворилась , що здохла .\n",
            "rus: _легла_ по дороге , аж смотрит – едет мужик со рыбой ; она и _притворилась_ , что сдохла .\n",
            "\n",
            "ukr: от мужик і говорить : \" возьму я оцю лисицю , обдеру да хоть шапку собі зошью \" .\n",
            "rus: из мужик и говорит : \" возьму мной ихнюю лисицу , _обдеру_ че хоть шапку себе _зошью_ \" .\n",
            "\n",
            "ukr: узяв да і положив ззаді у воза .\n",
            "rus: взял че и положил взади во телега .\n",
            "\n",
            "ukr: вона замітила , що мужик не смотрить , стала ногами викидувать рибу з воза , а когда побачила , що навикидала уже багато , тоди потихесеньку і сама злізла ; сіла біля риби да і їсть собі , - коли біжить оп'ять той самий вовчик .\n",
            "rus: она заметила , что мужик не _смотрить_ , стала ногами _викидувать_ рыбу со телега , а .когда увидела , что _навикидала_ уже много , тоды _потихесеньку_ и сама слезла ; присела возле рыбы че и ест себе , – когда бежит т со пять тот самый _вовчик_ .\n",
            "\n",
            "ukr: побачивши , що вона їсть рибу , прибіг до їй да й каже : \" здорово була , лисичко - сестричко !\n",
            "rus: увидев , что она ест рыбу , прибежал к им че и говорит : \" здорово была , _лисичко_ – сестричка !\n",
            "\n",
            "ukr: де се ти набрала стільки риби ? \"\n",
            "rus: куда ой ты набрала столько рыбы ? \"\n",
            "\n",
            "ukr: вона каже : \" наловила , вовчику - братику ! \"\n",
            "rus: она говорит : \" _наловила_ , _вовчику_ – братику ! \"\n",
            "\n",
            "ukr: а собі на думці : \" подожди , і я зроблю з тобою таку штуку , як і ти зо мною \" .\n",
            "rus: а себе по мнении : \" _подожди_ , и мной сделаю со тобой такую штуку , как и ты За мной \" .\n",
            "\n",
            "ukr: - \" як же ти ловила ? \"\n",
            "rus: – \" как то ты ловила ? \"\n",
            "\n",
            "ukr: - \" так , вовчику , уложила хвостик в ополонку , вожу тихенько да й кажу ; ловися , рибка , мала і велика !\n",
            "rus: – \" так , _вовчику_ , _уложила_ хвостик во прорубь , вожу тихонько че и говорю ; _ловися_ , рыбка , имела и большая !\n",
            "\n",
            "ukr: коли хочеш , то і ти піди , налови собі \" .\n",
            "rus: когда хочешь , то и ты пойди , _налови_ себе \" .\n",
            "\n",
            "ukr: він побіг да зробив так , як казала лисичка .\n",
            "rus: он побежал че сделал так , как говорила лисичка .\n",
            "\n",
            "ukr: а лисичка стала за деревом да й дивиться ; коли у вовчика зовсім хвостик примерз , вона тоді побігла в село да й кричить : \" ідіть , люди , вбивайте вовка ! \"\n",
            "rus: а лисичка стала за деревом че и смотрит ; когда во _вовчика_ совсем хвостик _примерз_ , она тогда побежала во село че и кричит : \" идите , люди , убивайте волка ! \"\n",
            "\n",
            "ukr: люди набігли з кольями да і убили його .\n",
            "rus: люди полезли со _кольями_ че и убили его .\n",
            "\n",
            "ukr: \n",
            "rus: \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjbLtmRqxElS",
        "colab_type": "text"
      },
      "source": [
        "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtNye1kEw3lQ",
        "colab_type": "text"
      },
      "source": [
        "## Оценка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG_W1NwVw_wp",
        "colab_type": "code",
        "outputId": "d0a35bb0-5bd0-4b2b-b6fe-dc1fe731b464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "map_precision_1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "map_precision_5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANYp1Kf2xUmS",
        "colab_type": "code",
        "outputId": "7ae07cad-266b-4d55-8087-c88ee0a66d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "svd_precision_1 = precision(uk_ru_test, np.matmul(X_test, W), 1)\n",
        "svd_precision_5 = precision(uk_ru_test, np.matmul(X_test, W), 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "87f0e035-6300-41f9-fba7-f81065a68d2e",
        "id": "HJnMR8I_Ue1r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('''\\tRegression\\t\\tSVD\n",
        "TOP-1:\\t{}\\t{}\n",
        "TOP-5:\\t{}\\t{}\n",
        "'''.format(map_precision_1, map_precision_5, svd_precision_1, svd_precision_5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tRegression\t\tSVD\n",
            "TOP-1:\t0.6356589147286822\t0.813953488372093\n",
            "TOP-5:\t0.6537467700258398\t0.8242894056847545\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}